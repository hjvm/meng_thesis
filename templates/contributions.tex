%% This is an example contributions chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter*{Contributions}
\addcontentsline{toc}{chapter}{Contributions}

This thesis has reviewed current empirical methods of assessing the KoL of LMs, and found that to date there exists no test of KoL that is comprehensive in its coverage of linguistic phenomena, is backed by attested and replicable human judgement data, and tests LMs' ability to track different linguistic phenomena across the full range of the acceptability gradient.  This thesis addresses this gap by proposing the three necessary components needed to construct such a comprehensive test of KoL.

First, this thesis presents the LI-Adger dataset, a collection of 150 pairwise phenomena collected by Sprouse et al. (2013) from Linguistic Inquiry (LI) 2001-2010, and an additional 105 multi-condition phenomena collected by Sprouse \& Almeida (2012) from an exhaustive selection of 219 sentence types from Adger's (2003) \textit{Core Syntax} textbook.  The phenomena represented in the LI-Adger dataset far exceed the coverage of the most recent datasets published to date for the purposes of testing the KoL in LMs.  The Corpus of Linguistic Acceptability (CoLA; Warstadt \& Bowman 2019) and The Benchmark of Linguistic Minimal Pairs for English (BLiMP; Warstadt et al. 2020).

This thesis supports the LI-Adger dataset with statistically powerful, replicable and validated human Magnitude Estimate (ME) data collected by Sprouse et al (2013) and Sprouse \& Almeida (2012).  The data accompanying the LI dataset boasts a 95 percent $\pm5$ minimum replication rate (Sprouse et al. 2013), whereas the ME data in the Adger dataset increases the minimum replication rate to over 97\% (Sprouse \& Almeida 2012)..  Additionally, Sprouse et al. (2018) determined the statistical power of both the LI and Adger datasets to meet the 80\% power threshold for the detection of False Negatives.

This dataset and accompanying human judgements then become the gold standard in terms of coverage and reliability.  In order to make full use of this dataset, this thesis proposes the Acceptability Delta Criterion, a metric that tests LMs for Human KoL by enforcing the gradience of acceptability and requiring LMs to track the validated human judgements through the gradient spectrum as the acceptability values change across minimal pairs.  We demonstrate further that adopting a functionally categorical view of acceptability leads to an unstable BERT model when fine-tuned with CoLA achieving 94\% correct classification of the minimal pairs in the LI-Adger dataset; while a trigram model trained on the British National Corpus (BNC) by Sprouse et al. 2018 achieves (75\%).  These results imply that either trigram models are able to account for 75\% of the phenomena in Generative grammar, or, alternatively, that treating acceptability as a categorical metric leads to a high false positive rate in KoL tests.  Accordingly, the ADC with a strict $\delta=0.5$ determined that neither BERT, whose predictions were nearly all categorical, and the trigram model both only correctly accounted for roughly 30\% of the minimal pairs in the LI-Adger dataset.  Using the defaul BERT models with gradient \textit{pseudo log-likelihood} (PLL) outputs increased its score to (37\%), further demonstrating the need for gradience in order to meet the ADC.

The three main contributions of this thesis when used together create the most comprehensive test of Human KoL for LMs currently available.  With further ongoing work, the test will also allow us to see a fine-grained analysis of which phenomena a LM was able to account for in its output and how well it predicted the acceptability judgements around them.  It is to be hoped that researchers will adopt the LI-Adger dataset for its coverage of Generative grammar and rely on the human judgements as the ground-truth labels that LMs are expected to approximate, and, beyond that, the ADC.